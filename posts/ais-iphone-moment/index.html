<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Voice&#39;s impending iPhone moment | José de la Puente | Python and Platform engineering</title>
<meta name="keywords" content="ai, llm, ui/ux, interface design">
<meta name="description" content="Better LLM models and more efficient microprocessor architectures will lead to a new dominant interface: voice.">
<meta name="author" content="">
<link rel="canonical" href="https://josedelapuente.com/posts/ais-iphone-moment/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.07bf49839e92734c439e460bc8db0e3fafc1e6322f5523cee1f520bdad544c62.css" integrity="sha256-B79Jg56Sc0xDnkYLyNsOP6/B5jIvVSPO4fUgva1UTGI=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://josedelapuente.com/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://josedelapuente.com/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://josedelapuente.com/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://josedelapuente.com/apple-touch-icon.png">
<link rel="mask-icon" href="https://josedelapuente.com/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://josedelapuente.com/posts/ais-iphone-moment/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript><meta property="og:url" content="https://josedelapuente.com/posts/ais-iphone-moment/">
  <meta property="og:site_name" content="José de la Puente | Python and Platform engineering">
  <meta property="og:title" content="Voice&#39;s impending iPhone moment">
  <meta property="og:description" content="Better LLM models and more efficient microprocessor architectures will lead to a new dominant interface: voice.">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-02-03T00:00:00+00:00">
    <meta property="article:modified_time" content="2024-02-03T00:00:00+00:00">
    <meta property="article:tag" content="Ai">
    <meta property="article:tag" content="Llm">
    <meta property="article:tag" content="Ui/Ux">
    <meta property="article:tag" content="Interface Design">
      <meta property="og:image" content="https://josedelapuente.com/images/The_Fighting_Temeraire,_JMW_Turner,_National_Gallery.jpg">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://josedelapuente.com/images/The_Fighting_Temeraire,_JMW_Turner,_National_Gallery.jpg">
<meta name="twitter:title" content="Voice&#39;s impending iPhone moment">
<meta name="twitter:description" content="Better LLM models and more efficient microprocessor architectures will lead to a new dominant interface: voice.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://josedelapuente.com/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Voice's impending iPhone moment",
      "item": "https://josedelapuente.com/posts/ais-iphone-moment/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Voice's impending iPhone moment",
  "name": "Voice\u0027s impending iPhone moment",
  "description": "Better LLM models and more efficient microprocessor architectures will lead to a new dominant interface: voice.",
  "keywords": [
    "ai", "llm", "ui/ux", "interface design"
  ],
  "articleBody": "Ben Thompson recently wrote in Stratechery about “The Impending VR Moment” (link).\nI’d summarize his argument as:\nRecent AI models (like Sora) show major improvements in generating complex and photorealistic video content that may be useful for virtual reality experiences (despite its limitations in how it represents the physical world) Transformer-based models like Sora will run much more quickly in chips with architectures designed for their computational needs rather than GPUs, like Groq has shown (link) Thus, we’re directed towards an “iPhone moment” for VR given the development of these technologies and AI, and VR hardware like the Apple Vision Pro or Meta Quest I think Ben’s right, but I also think it misses an equally significant moment: these same drivers will make voice the next dominant interface.\n“So three things: a widescreen iPod with touch controls, a revolutionary mobile phone and a breakthrough internet communications device. An iPod, a phone, and an internet communicator… Are you getting it?”\nThe iPhone — and all succeeding smartphones — collapsed all devices into 1. It replaced paper maps (does anyone use them anymore?), personal music players like the iPod or Walkman, long-distance phone calls through WhatsApp, cameras, newspapers and magazines, the TV and radio… and so much more.\nWe went from many devices to one: a monochromatic rectangle with a touchscreen.\nBut language is our original interface — hundreds of thousands if not millions of years old. No wonder why old people struggle with new technologies but can still solve problems by talking with others.\nMy former teacher, the inspiring Javier Cañada, recently spoke about why he thinks voice is the best interface. He described voice as:\nInmaterial: it doesn’t take space, unlike pixels on a screen Freeing up the senses: you don’t need to use multiple senses simultaneously (unlike sight and gesture with graphical interfaces) Accessible: it’s an interface almost everyone case use because you just need to speak Emotive: voice has intonation, which conveys information about the meaning of our words Personality: we all speak in a unique way This is much more expressive, intuitive, and personal than gestures on a smartphone screen, and a key reason for why I think the natural interface for AI agents is voice.\nReinventing hardware around voice The above leads to my main predictions for the next 10 years:\nVoice will be the dominant new interface of the next decade This will create a long-tail of hardware around voice While we’re not exactly there, better computation — leading to faster and more accurate LLM results — should enable this. Some early example of this are the Rabbit R1 and the Humane Pin.\nWhile smartphones will continue to exist because of the value of displaying information on screens (just like desktops and laptops coexisted with smartphones), these new devices will complement — or in some cases even substitute — smartphones.\nI’m particularly excited about these devices eventually being substitutes of smartphones. Our phones are essential but invasive: we can’t imagine not having it, but its interruptions and distractions have few limits. Something like a screen-less smartwatch that can still do the essentials like access our calendar, call our Uber, or make a call, can be a full replacement to smartphones for many people — especially those sensitive to smartphone’s invasiveness.\nTo extend this further, I think we’ll see the reverse trend from the smartphone: instead of collapsing all devices into one, we’ll see an explosion of a long-tail of AI-powered devices. With an internet connection to make calls to an LLM, and maybe some additional hardware like cameras to understand the user’s environment, you can make devices more helpful. Imagine a mining hat with a camera that helps you understand the geological conditions around you and security cameras that help show the type of recorded footage you’re looking for.\nJust like vertical SaaS helps you deliver more value to customers with more tailored products, “vertical” AI-powered hardware should provide more consumer value for specific use cases than generic alternatives.\n",
  "wordCount" : "664",
  "inLanguage": "en",
  "image": "https://josedelapuente.com/images/The_Fighting_Temeraire,_JMW_Turner,_National_Gallery.jpg","datePublished": "2024-02-03T00:00:00Z",
  "dateModified": "2024-02-03T00:00:00Z",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://josedelapuente.com/posts/ais-iphone-moment/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "José de la Puente | Python and Platform engineering",
    "logo": {
      "@type": "ImageObject",
      "url": "https://josedelapuente.com/favicon.ico"
    }
  }
}
</script>
</head>

<body class=" dark" id="top">

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://josedelapuente.com/" accesskey="h" title="José de la Puente (Alt + H)">José de la Puente</a>
        </div>
        <ul id="menu">
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Voice&#39;s impending iPhone moment
    </h1>
    <div class="post-description">
      Better LLM models and more efficient microprocessor architectures will lead to a new dominant interface: voice.
    </div>
    <div class="post-meta"><span title='2024-02-03 00:00:00 +0000 UTC'>February 3, 2024</span>

</div>
  </header> 
  <div class="post-content"><p>Ben Thompson recently wrote in Stratechery about &ldquo;The Impending VR Moment&rdquo; (<a href="https://stratechery.com/2024/sora-groq-and-virtual-reality/">link</a>).</p>
<p>I&rsquo;d summarize his argument as:</p>
<ul>
<li>Recent AI models (like Sora) show major improvements in generating complex and photorealistic video content that may be useful for virtual reality experiences (despite its limitations in how it represents the physical world)</li>
<li>Transformer-based models like Sora will run much more quickly in chips with architectures designed for their computational needs rather than GPUs, like Groq has shown (<a href="https://groq.com/">link</a>)</li>
<li>Thus,  we&rsquo;re directed towards an &ldquo;iPhone moment&rdquo; for VR given the development of these technologies and AI, and VR hardware like the Apple Vision Pro or Meta Quest</li>
</ul>
<p>I think Ben&rsquo;s right, but I also think it misses an equally significant moment: these same drivers will make voice the next dominant interface.</p>
<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
      <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/GK55ElsVzxM?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video"></iframe>
    </div>

<blockquote>
<p>&ldquo;So three things: a widescreen iPod with touch controls, a revolutionary mobile phone and a breakthrough internet communications device. An iPod, a phone, and an internet communicator&hellip; Are you getting it?&rdquo;</p></blockquote>
<p>The iPhone — and all succeeding smartphones — collapsed all devices into 1. It replaced paper maps (does anyone use them anymore?), personal music players like the iPod or Walkman, long-distance phone calls through WhatsApp, cameras, newspapers and magazines, the TV and radio&hellip; and so much more.</p>
<p>We went from many devices to one: a monochromatic rectangle with a touchscreen.</p>
<p>But language is our original interface — hundreds of thousands if not millions of years old. No wonder why old people struggle with new technologies but can still solve problems by talking with others.</p>
<p>My former teacher, the inspiring Javier Cañada, recently spoke about why he thinks voice is the best interface. He described voice as:</p>
<ul>
<li>Inmaterial: it doesn&rsquo;t take space, unlike pixels on a screen</li>
<li>Freeing up the senses: you don&rsquo;t need to use multiple senses simultaneously (unlike sight and gesture with graphical interfaces)</li>
<li>Accessible: it&rsquo;s an interface almost everyone case use because you just need to speak</li>
<li>Emotive: voice has intonation, which conveys information about the meaning of our words</li>
<li>Personality: we all speak in a unique way</li>
</ul>
<p>This is much more expressive, intuitive, and personal than gestures on a smartphone screen, and a key reason for why I think the natural interface for AI agents is voice.</p>
<h2 id="reinventing-hardware-around-voice">Reinventing hardware around voice<a hidden class="anchor" aria-hidden="true" href="#reinventing-hardware-around-voice">#</a></h2>
<p>The above leads to my main predictions for the next 10 years:</p>
<ol>
<li>Voice will be the dominant new interface of the next decade</li>
<li>This will create a long-tail of hardware around voice</li>
</ol>
<p>While we&rsquo;re not exactly there, better computation — leading to faster and more accurate LLM results — should enable this. Some early example of this are the <a href="https://www.rabbit.tech/keynote">Rabbit R1</a> and the <a href="https://humane.com/aipin">Humane Pin</a>.</p>
<p>While smartphones will continue to exist because of the value of displaying information on screens (just like desktops and laptops coexisted with smartphones), these new devices will complement — or in some cases even substitute — smartphones.</p>
<p>I&rsquo;m particularly excited about these devices eventually being <em>substitutes</em> of smartphones. Our phones are essential but invasive: we can&rsquo;t imagine not having it, but its interruptions and distractions have few limits. Something like a screen-less smartwatch that can still do the essentials like access our calendar, call our Uber, or make a call, can be a full replacement to smartphones for many people — especially those sensitive to smartphone&rsquo;s invasiveness.</p>
<p>To extend this further, I think we&rsquo;ll see the reverse trend from the smartphone: instead of collapsing all devices into one, we&rsquo;ll see an explosion of a long-tail of AI-powered devices. With an internet connection to make calls to an LLM, and maybe some additional hardware like cameras to understand the user&rsquo;s environment, you can make devices more helpful. Imagine a mining hat with a camera that helps you understand the geological conditions around you and security cameras that help show the type of recorded footage you&rsquo;re looking for.</p>
<p>Just like vertical SaaS helps you deliver more value to customers with more tailored products, &ldquo;vertical&rdquo; AI-powered hardware should provide more consumer value for specific use cases than generic alternatives.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://josedelapuente.com/tags/ai/">Ai</a></li>
      <li><a href="https://josedelapuente.com/tags/llm/">Llm</a></li>
      <li><a href="https://josedelapuente.com/tags/ui/ux/">Ui/Ux</a></li>
      <li><a href="https://josedelapuente.com/tags/interface-design/">Interface Design</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
</body>

</html>
